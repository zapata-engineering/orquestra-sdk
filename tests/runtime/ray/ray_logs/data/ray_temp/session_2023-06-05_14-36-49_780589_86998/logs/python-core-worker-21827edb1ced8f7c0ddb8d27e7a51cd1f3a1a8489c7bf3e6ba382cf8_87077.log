[2023-06-05 14:43:21,879 I 87077 2384029] core_worker_process.cc:107: Constructing CoreWorkerProcess. pid: 87077
[2023-06-05 14:43:21,882 I 87077 2384029] io_service_pool.cc:35: IOServicePool is running with 1 io_service.
[2023-06-05 14:43:21,883 I 87077 2384029] grpc_server.cc:140: worker server started, listening on port 10007.
[2023-06-05 14:43:21,888 I 87077 2384029] core_worker.cc:215: Initializing worker at address: 127.0.0.1:10007, worker ID 21827edb1ced8f7c0ddb8d27e7a51cd1f3a1a8489c7bf3e6ba382cf8, raylet 07b80dd30aae9db2094bf6c6864bd6fa3821de7b0bf1a56c61d8c0cb
[2023-06-05 14:43:21,890 I 87077 2384029] task_event_buffer.cc:149: Reporting task events to GCS every 1000ms.
[2023-06-05 14:43:21,891 I 87077 2384061] accessor.cc:590: Received notification for node id = 07b80dd30aae9db2094bf6c6864bd6fa3821de7b0bf1a56c61d8c0cb, IsAlive = 1
[2023-06-05 14:43:21,891 I 87077 2384029] core_worker.cc:602: Adjusted worker niceness to 15
[2023-06-05 14:43:21,891 I 87077 2384061] core_worker.cc:3847: Number of alive nodes:1
[2023-06-05 14:43:21,891 I 87077 2384061] core_worker.cc:550: Event stats:


Global stats: 12 total (7 active)
Queueing time: mean = 23.167 us, max = 124.000 us, min = 14.000 us, total = 278.000 us
Execution time:  mean = 26.333 us, total = 316.000 us
Event stats:
	PeriodicalRunner.RunFnPeriodically - 6 total (4 active, 1 running), CPU time: mean = 8.667 us, total = 52.000 us
	UNKNOWN - 2 total (2 active), CPU time: mean = 0.000 s, total = 0.000 s
	InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
	WorkerInfoGcsService.grpc_client.AddWorkerInfo - 1 total (0 active), CPU time: mean = 16.000 us, total = 16.000 us
	InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 1 total (0 active), CPU time: mean = 104.000 us, total = 104.000 us
	NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), CPU time: mean = 144.000 us, total = 144.000 us

-----------------
Task Event stats:

IO Service Stats:

Global stats: 2 total (1 active)
Queueing time: mean = 3.500 us, max = 7.000 us, min = 7.000 us, total = 7.000 us
Execution time:  mean = 7.000 us, total = 14.000 us
Event stats:
	PeriodicalRunner.RunFnPeriodically - 1 total (0 active), CPU time: mean = 14.000 us, total = 14.000 us
	CoreWorker.deadline_timer.flush_task_events - 1 total (1 active), CPU time: mean = 0.000 s, total = 0.000 s
Other Stats:
	grpc_in_progress:0
	current number of task events in buffer: 0
	total task events sent: 0 MiB
	total number of task events sent: 0
	num status task events dropped: 0
	num profile task events dropped: 0


[2023-06-05 14:43:29,165 I 87077 2384029] direct_actor_task_submitter.cc:36: Set max pending calls to 0 for actor 2173a9b85e42ff89348b7fbf01000000
[2023-06-05 14:43:29,168 I 87077 2384029] direct_actor_task_submitter.cc:36: Set max pending calls to 0 for actor 2173a9b85e42ff89348b7fbf01000000
[2023-06-05 14:43:34,756 I 87077 2384061] core_worker.cc:711: Exit signal received, this process will exit after all outstanding tasks have finished, exit_type=INTENDED_SYSTEM_EXIT, detail=Worker exits because it was idle (it doesn't have objects it owns while no task or actor has been scheduled) for a long time.
[2023-06-05 14:43:34,757 I 87077 2384029] core_worker.cc:698: Disconnecting to the raylet.
[2023-06-05 14:43:34,757 I 87077 2384029] raylet_client.cc:163: RayletClient::Disconnect, exit_type=INTENDED_SYSTEM_EXIT, exit_detail=Worker exits because it was idle (it doesn't have objects it owns while no task or actor has been scheduled) for a long time., has creation_task_exception_pb_bytes=0
[2023-06-05 14:43:34,757 I 87077 2384029] core_worker.cc:621: Shutting down a core worker.
[2023-06-05 14:43:34,757 I 87077 2384029] task_event_buffer.cc:160: Shutting down TaskEventBuffer.
[2023-06-05 14:43:34,758 I 87077 2384067] task_event_buffer.cc:142: Task event buffer io service stopped.
[2023-06-05 14:43:34,758 I 87077 2384029] core_worker.cc:647: Disconnecting a GCS client.
[2023-06-05 14:43:34,758 I 87077 2384029] core_worker.cc:651: Waiting for joining a core worker io thread. If it hangs here, there might be deadlock or a high load in the core worker io service.
[2023-06-05 14:43:34,758 I 87077 2384061] core_worker.cc:798: Core worker main io service stopped.
[2023-06-05 14:43:34,763 I 87077 2384029] core_worker.cc:664: Core worker ready to be deallocated.
[2023-06-05 14:43:34,763 I 87077 2384029] core_worker_process.cc:243: Task execution loop terminated. Removing the global worker.
[2023-06-05 14:43:34,763 I 87077 2384029] core_worker.cc:612: Core worker is destructed
[2023-06-05 14:43:34,962 I 87077 2384029] core_worker_process.cc:147: Destructing CoreWorkerProcessImpl. pid: 87077
[2023-06-05 14:43:34,962 I 87077 2384029] io_service_pool.cc:47: IOServicePool is stopped.
